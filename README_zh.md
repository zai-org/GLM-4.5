# GLM-4.5

[Read this in English.](./README.md)

<p align="center">
    ğŸ‘‹ åŠ å…¥æˆ‘ä»¬çš„ <a href="resources/WECHAT.md" target="_blank">å¾®ä¿¡</a> å’Œ <a href="https://discord.com/invite/8cnQKdAprg" target="_blank">Discord</a> ç¤¾åŒºã€‚
    <br>
    ğŸ“– æŸ¥çœ‹ GLM-4.5 <a href="" target="_blank">æŠ€æœ¯åšå®¢</a> ã€‚
    <br>
    ğŸ“ åœ¨ <a href="https://www.bigmodel.cn/dev/api/visual-reasoning-model/GLM-4.5">æ™ºè°±å¤§æ¨¡å‹å¼€æ”¾å¹³å°</a> ä½¿ç”¨ GLM-4.5 çš„APIæœåŠ¡ã€‚
</p>

## æ¨¡å‹ä»‹ç»

## ä¸‹è½½æ¨¡å‹

| æ¨¡å‹               | ä¸‹è½½åœ°å€                                                                                                                                       | æƒé‡å¤§å°      | ç²¾åº¦   |
|------------------|--------------------------------------------------------------------------------------------------------------------------------------------|-----------|------|
| GLM-4.5          | [ğŸ¤—Hugging Face](https://huggingface.co/THUDM/GLM-4.5)<br> [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/GLM-4.5)                   | 355B-A32B | BF16 |
| GLM-4.5-Air      | [ğŸ¤—Hugging Face](https://huggingface.co/THUDM/GLM-4.5-Air)<br> [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/GLM-4.5-Air)           | 106B-A12B | BF16 |
| GLM-4.5-FP8      | [ğŸ¤—Hugging Face](https://huggingface.co/THUDM/GLM-4.5-FP8)<br> [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/GLM-4.5-FP8)           | 106B-A12B | FP8  |
| GLM-4.5-Air-FP8  | [ğŸ¤—Hugging Face](https://huggingface.co/THUDM/GLM-4.5-Air-FP8)<br> [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/GLM-4.5-Air-FP8)   | 106B-A12B | FP8  |
| GLM-4.5-Base     | [ğŸ¤—Hugging Face](https://huggingface.co/THUDM/GLM-4.5-Base)<br> [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/GLM-4.5-Base)         | 355B-A32B | BF16 |
| GLM-4.5-Air-Base | [ğŸ¤—Hugging Face](https://huggingface.co/THUDM/GLM-4.5-Air-Base)<br> [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/GLM-4.5-Air-Base) | 106B-A12B | BF16 |

æ¨¡å‹ç®—æ³•ä»£ç å¯ä»¥æŸ¥çœ‹ [transformers](https://github.com/huggingface/transformers/tree/main/src/transformers/models/glm4_moe)
çš„å®Œæ•´å®ç°ã€‚

## è¿è¡Œè¦æ±‚

+ ä»¥ä¸‹æ•°æ®å‡ä½¿ç”¨ `BF16`ç²¾åº¦å¾®è°ƒå’Œæ¨ç†ã€‚
+ ç›¸å…³é…ç½®ä¿¡æ¯ï¼š
    + æ“ä½œç³»ç»Ÿ: `Ubuntu 22.04`
    + CUDA ç‰ˆæœ¬: `12.8`
    + Python ç‰ˆæœ¬: `3.10.12`
    + å†…å­˜: `2TB`

æ•°æ®ä»…ä¾›å‚è€ƒ, å…·ä½“æ€§èƒ½æå‡ä»¥å¼€å‘è€…éƒ¨ç½²ä¸ºå‡†ã€‚

### æ¨ç† (SGLang)

| æ¨¡å‹          | è®¾å¤‡          | æ•°é‡ | è¾“å‡ºé€Ÿåº¦ |
|-------------|-------------|----|------|
| GLM-4.5     | NVIDIA H200 | 8  |      |
| GLM-4.5-Air | NVIDIA H200 | 4  |      |

### å¾®è°ƒ (LLaMA-Factory)

| æ¨¡å‹          | è®¾å¤‡(é›†ç¾¤)      | ç­–ç•¥         | éœ€è¦å¡æ•° | æ‰¹å¤§å° (per GPUs) |
|-------------|-------------|------------|------|----------------|
| GLM-4.5     | NVIDIA H100 | Lora ZERO3 | 16   | 1              |
| GLM-4.5-Air | NVIDIA H100 | Lora ZERO3 | 4    | 1              |

### å¾®è°ƒ (SWIFT)

| æ¨¡å‹          | è®¾å¤‡(é›†ç¾¤)      | ç­–ç•¥   | éœ€è¦å¡æ•° | æ‰¹å¤§å° (per GPUs) |
|-------------|-------------|------|------|----------------|
| GLM-4.5     | NVIDIA H100 | Lora | 16   | 1              |
| GLM-4.5-Air | NVIDIA H100 | Lora | 4    | 1              |
| GLM-4.5     | NVIDIA H100 | SFT  | 16   | 1              |
| GLM-4.5-Air | NVIDIA H100 | SFT  | 4    | 1              |
| GLM-4.5     | NVIDIA H100 | RL   | 16   | 1              |
| GLM-4.5-Air | NVIDIA H100 | RL   | 4    | 1              |

## å¿«é€Ÿä¸Šæ‰‹

è¯·æŒ‰ç…§ `requirements.txt` ä¸­çš„ä¾èµ–å®‰è£…ç›¸å…³åŒ…ã€‚

```shell
pip install -r requirements.txt
```

### transformers

è¯·æŸ¥çœ‹ `inference` æ–‡ä»¶å¤¹ä¸­çš„ `trans_infer_cli.py`ä»£ç ã€‚

### vLLM

+ BF16

```shell
vllm serve /mnt/GLM-4.5-FP8-0724 \
    --tensor-parallel-size 8 \
    --tool-call-parser glm45 \
    --reasoning-parser glm45 \
    --enable-auto-tool-choice \
    --served-model-name glm-4.5-air
```

### SGLang

+ BF16

```shell
python3 -m sglang.launch_server \
  --model-path THUDM/GLM-4.5-Air \
  --tp-size 8 \
  --tool-call-parser glm45  \
  --reasoning-parser glm45 \
  --speculative-algorithm EAGLE \
  --speculative-num-steps 3 \
  --speculative-eagle-topk 1 \
  --speculative-num-draft-tokens 4 \
  --mem-fraction-static 0.7 \
  --served-model-name glm-4.5-air
```

+ FP8

```shell
python3 -m sglang.launch_server \
  --model-path THUDM/GLM-4.5-Air-FP8 \
  --tp-size 4 \
  --tool-call-parser glm45  \
  --reasoning-parser glm45  \
  --speculative-algorithm EAGLE \
  --speculative-num-steps 3  \
  --speculative-eagle-topk 1  \
  --speculative-num-draft-tokens 4 \
  --mem-fraction-static 0.7 \
  --disable-shared-experts-fusion \
  --served-model-name glm-4.5-air-fp8
```

### è¯·æ±‚

+ ä½¿ç”¨`vLLM`å’Œ`SGLang`æ—¶ï¼Œå‘é€è¯·æ±‚æ—¶å€™é»˜è®¤æ€è€ƒï¼Œå¦‚æœå¸Œæœ›å…³é—­æ€è€ƒå¼€å…³ï¼Œåˆ™éœ€è¦å¢åŠ 
  `extra_body={"chat_template_kwargs": {"enable_thinking": False}}` å‚æ•°ã€‚
+ å‡æ”¯æŒå·¥å…·è°ƒç”¨ã€‚è¯·ä½¿ç”¨ OpenAI ç±»æ ¼å¼å·¥å…·æè¿°è°ƒç”¨ã€‚
+ å…·ä½“ä»£ç è¯·æŸ¥çœ‹`inference`æ–‡ä»¶å¤¹ä¸­çš„`api_request.py`ã€‚

## å¼•ç”¨è®ºæ–‡

å¦‚æœæ‚¨ä½¿ç”¨äº†æœ¬æ¨¡å‹ï¼Œè¯·å¼•ç”¨ä»¥ä¸‹è®ºæ–‡ï¼š

```bibtex

```
