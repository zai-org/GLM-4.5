# GLM-4.5

[English Version](./README.md)

<div align="center">
<img src=resources/logo.svg width="15%"/>
</div>
<p align="center">
    ğŸ‘‹ åŠ å…¥æˆ‘ä»¬çš„<a href="resources/WECHAT.md" target="_blank"> å¾®ä¿¡ç¾¤ </a>æˆ–<a href="https://discord.gg/QR7SARHRxK" target="_blank"> Discord </a>ç¤¾åŒºã€‚
    <br>
    ğŸ“– æŸ¥çœ‹GLM-4.5<a href="https://z.ai/blog/glm-4.5" target="_blank"> æŠ€æœ¯åšå®¢ </a> ï¼Œ <a href="resources/GLM_4_5_technical_report.pdf" target="_blank"> æŠ€æœ¯æŠ¥å‘Š </a> ä»¥åŠ <a href="https://zhipu-ai.feishu.cn/wiki/Gv3swM0Yci7w7Zke9E0crhU7n7D" target="_blank"> æ™ºè°±AIæŠ€æœ¯æ–‡æ¡£ </a>ã€‚
    <br>
    ğŸ“ åœ¨<a href="https://docs.bigmodel.cn/cn/guide/models/text/glm-4.5"> æ™ºè°±AIå¼€æ”¾å¹³å° </a>ä¸Šä½¿ç”¨GLM-4.5 APIæœåŠ¡ã€‚
    <br>
    ğŸ‘‰ ä¸€é”®ä½“éªŒ <a href="https://chat.z.ai" >GLM-4.5 </a>ã€‚
</p>

## æ¨¡å‹ä»‹ç»

**GLM-4.5** ç³»åˆ—æ¨¡å‹æ˜¯ä¸“ä¸ºæ™ºèƒ½ä½“è®¾è®¡çš„åŸºç¡€æ¨¡å‹ã€‚GLM-4.5æ‹¥æœ‰ **3550** äº¿æ€»å‚æ•°é‡ï¼Œå…¶ä¸­ **320** äº¿æ´»è·ƒå‚æ•°ï¼›GLM-4.5-Air é‡‡ç”¨æ›´ç´§å‡‘çš„è®¾è®¡ï¼Œæ‹¥æœ‰
 **1060** äº¿æ€»å‚æ•°é‡ï¼Œå…¶ä¸­ **120** äº¿æ´»è·ƒå‚æ•°ã€‚GLM-4.5æ¨¡å‹ç»Ÿä¸€äº†æ¨ç†ã€ç¼–ç å’Œæ™ºèƒ½ä½“èƒ½åŠ›ï¼Œä»¥æ»¡è¶³æ™ºèƒ½ä½“åº”ç”¨çš„å¤æ‚éœ€æ±‚ã€‚

GLM-4.5 å’Œ GLM-4.5-Air éƒ½æ˜¯æ··åˆæ¨ç†æ¨¡å‹ï¼Œæä¾›ä¸¤ç§æ¨¡å¼ï¼šç”¨äºå¤æ‚æ¨ç†å’Œå·¥å…·ä½¿ç”¨çš„æ€è€ƒæ¨¡å¼ï¼Œä»¥åŠç”¨äºå³æ—¶å“åº”çš„éæ€è€ƒæ¨¡å¼ã€‚

æˆ‘ä»¬å·²å¼€æºäº† GLM-4.5 å’Œ GLM-4.5-Air çš„åŸºç¡€æ¨¡å‹ã€æ··åˆæ¨ç†æ¨¡å‹ä»¥åŠæ··åˆæ¨ç†æ¨¡å‹çš„FP8ç‰ˆæœ¬ã€‚å®ƒä»¬é‡‡ç”¨MITå¼€æºè®¸å¯è¯å‘å¸ƒï¼Œå¯ç”¨äºå•†ä¸šç”¨é€”å’ŒäºŒæ¬¡å¼€å‘ã€‚

åœ¨æˆ‘ä»¬å¯¹12é¡¹è¡Œä¸šæ ‡å‡†åŸºå‡†çš„å…¨é¢è¯„ä¼°ä¸­ï¼ŒGLM-4.5è¡¨ç°å“è¶Šï¼Œå¾—åˆ† **63.2**ï¼Œåœ¨æ‰€æœ‰ä¸“æœ‰å’Œå¼€æºæ¨¡å‹ä¸­æ’å**ç¬¬3**
ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒGLM-4.5-Airåœ¨ä¿æŒä¼˜å¼‚æ•ˆç‡çš„åŒæ—¶ï¼Œä»å–å¾—äº† **59.8** çš„ç«äº‰æ€§æˆç»©ã€‚

![bench](resources/bench.png)

å¦‚éœ€äº†è§£æ›´å¤šè¯„ä¼°ç»“æœã€å±•ç¤ºæ¡ˆä¾‹å’ŒæŠ€æœ¯ç»†èŠ‚ï¼Œè¯·è®¿é—®æˆ‘ä»¬çš„ [æŠ€æœ¯æŠ¥å‘Š](resources/GLM_4_5_technical_report.pdf) æˆ–è€… [æŠ€æœ¯åšå®¢](https://z.ai/blog/glm-4.5)ã€‚

æ¨¡å‹ä»£ç ã€å·¥å…·è§£æå™¨å’Œæ¨ç†è§£æå™¨å¯åœ¨ [transformers](https://github.com/huggingface/transformers/tree/main/src/transformers/models/glm4_moe)ã€ [vLLM](https://github.com/vllm-project/vllm/blob/main/vllm/model_executor/models/glm4_moe_mtp.py)
å’Œ [SGLang](https://github.com/sgl-project/sglang/blob/main/python/sglang/srt/models/glm4_moe.py) çš„æ‰¾åˆ°å…·ä½“å®ç°ã€‚

## æ¨¡å‹ä¸‹è½½

ä½ å¯ä»¥åœ¨ [Hugging Face](https://huggingface.co/spaces/zai-org/GLM-4.5-Space)
æˆ– [ModelScope](https://modelscope.cn/studios/ZhipuAI/GLM-4.5-Demo) ä¸Šç›´æ¥ä½“éªŒæ¨¡å‹ï¼Œä¹Ÿå¯ä»¥æŒ‰ç…§ä¸‹é¢çš„é“¾æ¥ä¸‹è½½æ¨¡å‹ã€‚

| æ¨¡å‹               | ä¸‹è½½é“¾æ¥                                                                                                                                          | æ¨¡å‹å¤§å°      | ç²¾åº¦   |
|------------------|-----------------------------------------------------------------------------------------------------------------------------------------------|-----------|------|
| GLM-4.5          | [ğŸ¤— Hugging Face](https://huggingface.co/zai-org/GLM-4.5)<br> [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/GLM-4.5)                   | 355B-A32B | BF16 |
| GLM-4.5-Air      | [ğŸ¤— Hugging Face](https://huggingface.co/zai-org/GLM-4.5-Air)<br> [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/GLM-4.5-Air)           | 106B-A12B | BF16 |
| GLM-4.5-FP8      | [ğŸ¤— Hugging Face](https://huggingface.co/zai-org/GLM-4.5-FP8)<br> [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/GLM-4.5-FP8)           | 355B-A32B | FP8  |
| GLM-4.5-Air-FP8  | [ğŸ¤— Hugging Face](https://huggingface.co/zai-org/GLM-4.5-Air-FP8)<br> [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/GLM-4.5-Air-FP8)   | 106B-A12B | FP8  |
| GLM-4.5-Base     | [ğŸ¤— Hugging Face](https://huggingface.co/zai-org/GLM-4.5-Base)<br> [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/GLM-4.5-Base)         | 355B-A32B | BF16 |
| GLM-4.5-Air-Base | [ğŸ¤— Hugging Face](https://huggingface.co/zai-org/GLM-4.5-Air-Base)<br> [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/GLM-4.5-Air-Base) | 106B-A12B | BF16 |

## ç³»ç»Ÿè¦æ±‚

### æ¨ç†

æˆ‘ä»¬æä¾›äº†"å…¨åŠŸèƒ½"æ¨¡å‹æ¨ç†çš„æœ€ä½å’Œæ¨èé…ç½®ã€‚ä¸‹è¡¨ä¸­çš„æ•°æ®åŸºäºä»¥ä¸‹æ¡ä»¶ï¼š

1. æ‰€æœ‰æ¨¡å‹éƒ½ä½¿ç”¨MTPå±‚ï¼Œå¹¶æŒ‡å®š`--speculative-num-steps 3 --speculative-eagle-topk 1 --speculative-num-draft-tokens 4`
   ä»¥ç¡®ä¿å…·æœ‰ç«äº‰åŠ›çš„æ¨ç†é€Ÿåº¦ã€‚
2. ä¸ä½¿ç”¨ `cpu-offload` å‚æ•°ã€‚
3. æ¨ç†æ‰¹å¤„ç†å¤§å°ä¸è¶…è¿‡ `8`ã€‚
4. æ‰€æœ‰æ“ä½œéƒ½åœ¨åŸç”Ÿæ”¯æŒFP8æ¨ç†çš„è®¾å¤‡ä¸Šæ‰§è¡Œï¼Œç¡®ä¿æƒé‡å’Œç¼“å­˜éƒ½é‡‡ç”¨FP8æ ¼å¼ã€‚
5. æœåŠ¡å™¨å†…å­˜å¿…é¡»è¶…è¿‡ `1T` ä»¥ç¡®ä¿æ­£å¸¸çš„æ¨¡å‹åŠ è½½å’Œè¿è¡Œã€‚

æ¨¡å‹å¯åœ¨ä¸‹è¡¨é…ç½®ä¸‹è¿è¡Œï¼š

| æ¨¡å‹          | ç²¾åº¦   | GPUç±»å‹å’Œæ•°é‡             | æµ‹è¯•æ¡†æ¶   |
|-------------|------|----------------------|--------|
| GLM-4.5     | BF16 | H100 x 16 / H200 x 8 | sglang |
| GLM-4.5     | FP8  | H100 x 8 / H200 x 4  | sglang |
| GLM-4.5-Air | BF16 | H100 x 4 / H200 x 2  | sglang |
| GLM-4.5-Air | FP8  | H100 x 2 / H200 x 1  | sglang |

åœ¨ä¸‹è¡¨é…ç½®ä¸‹ï¼Œæ¨¡å‹å¯ä»¥å……åˆ†åˆ©ç”¨å…¶128Kä¸Šä¸‹æ–‡é•¿åº¦ï¼š

| æ¨¡å‹          | ç²¾åº¦   | GPUç±»å‹å’Œæ•°é‡              | æµ‹è¯•æ¡†æ¶   |
|-------------|------|-----------------------|--------|
| GLM-4.5     | BF16 | H100 x 32 / H200 x 16 | sglang |
| GLM-4.5     | FP8  | H100 x 16 / H200 x 8  | sglang |
| GLM-4.5-Air | BF16 | H100 x 8 / H200 x 4   | sglang |
| GLM-4.5-Air | FP8  | H100 x 4 / H200 x 2   | sglang |

### å¾®è°ƒ

ä½¿ç”¨ [Llama Factory](https://github.com/hiyouga/LLaMA-Factory) æ¡†æ¶ï¼Œä»£ç å¯åœ¨ä¸‹è¡¨é…ç½®ä¸‹è¿è¡Œï¼š

| æ¨¡å‹          | GPUç±»å‹å’Œæ•°é‡  | ç­–ç•¥   | æ‰¹å¤„ç†å¤§å°ï¼ˆæ¯GPUï¼‰ |
|-------------|-----------|------|-------------|
| GLM-4.5     | H100 x 16 | Lora | 1           |
| GLM-4.5-Air | H100 x 4  | Lora | 1           |

ä½¿ç”¨ [Swift](https://github.com/modelscope/ms-swift) æ¡†æ¶ï¼Œä»£ç å¯åœ¨ä¸‹è¡¨é…ç½®ä¸‹è¿è¡Œï¼š

| æ¨¡å‹          | GPUç±»å‹å’Œæ•°é‡          | ç­–ç•¥   | æ‰¹å¤„ç†å¤§å°ï¼ˆæ¯GPUï¼‰ |
|-------------|-------------------|------|-------------|
| GLM-4.5     | H20 (96GiB) x 16  | Lora | 1           |
| GLM-4.5-Air | H20 (96GiB) x 4   | Lora | 1           |
| GLM-4.5     | H20 (96GiB) x 128 | SFT  | 1           |
| GLM-4.5-Air | H20 (96GiB) x 32  | SFT  | 1           |
| GLM-4.5     | H20 (96GiB) x 128 | RL   | 1           |
| GLM-4.5-Air | H20 (96GiB) x 32  | RL   | 1           |

## å¿«é€Ÿå¼€å§‹

è¯·æ ¹æ®`requirements.txt`å®‰è£…æ‰€éœ€çš„åŒ…ã€‚

```shell
pip install -r requirements.txt
```

### transformers

è¯·å‚è€ƒ `inference` æ–‡ä»¶å¤¹ä¸­çš„ `trans_infer_cli.py` ä»£ç ã€‚

### vLLM

+ BF16å’ŒFP8éƒ½å¯ä»¥ç”¨ä»¥ä¸‹ä»£ç å¯åŠ¨ï¼š

```shell
vllm serve zai-org/GLM-4.5-Air \
    --tensor-parallel-size 8 \
    --tool-call-parser glm45 \
    --reasoning-parser glm45 \
    --enable-auto-tool-choice \
    --served-model-name glm-4.5-air
```

å¦‚æœæ‚¨ä½¿ç”¨8x H100 GPUå¹¶ä¸”åœ¨è¿è¡ŒGLM-4.5æ¨¡å‹æ—¶é‡åˆ°å†…å­˜ä¸è¶³çš„é—®é¢˜ï¼Œæ‚¨éœ€è¦ä½¿ç”¨`--cpu-offload-gb 16`ï¼ˆä»…é€‚ç”¨äºvLLMï¼‰ã€‚

å¦‚æœé‡åˆ°`flash infer`é—®é¢˜ï¼Œè¯·ä½¿ç”¨`VLLM_ATTENTION_BACKEND=XFORMERS`ä½œä¸ºä¸´æ—¶æ›¿ä»£æ–¹æ¡ˆã€‚æ‚¨ä¹Ÿå¯ä»¥æŒ‡å®š
`TORCH_CUDA_ARCH_LIST='9.0+PTX'`æ¥ä½¿ç”¨`flash infer`ï¼ˆä¸åŒGPUæœ‰ä¸åŒçš„TORCH_CUDA_ARCH_LISTå€¼ï¼Œè¯·ç›¸åº”æ£€æŸ¥ï¼‰ã€‚

### SGLang

+ BF16

```shell
python3 -m sglang.launch_server \
  --model-path zai-org/GLM-4.5-Air \
  --tp-size 8 \
  --tool-call-parser glm45  \
  --reasoning-parser glm45 \
  --speculative-algorithm EAGLE \
  --speculative-num-steps 3 \
  --speculative-eagle-topk 1 \
  --speculative-num-draft-tokens 4 \
  --mem-fraction-static 0.7 \
  --served-model-name glm-4.5-air \
  --host 0.0.0.0 \
  --port 8000
```

+ FP8

```shell
python3 -m sglang.launch_server \
  --model-path zai-org/GLM-4.5-Air-FP8 \
  --tp-size 4 \
  --tool-call-parser glm45  \
  --reasoning-parser glm45  \
  --speculative-algorithm EAGLE \
  --speculative-num-steps 3  \
  --speculative-eagle-topk 1  \
  --speculative-num-draft-tokens 4 \
  --mem-fraction-static 0.7 \
  --disable-shared-experts-fusion \
  --served-model-name glm-4.5-air-fp8 \
  --host 0.0.0.0 \
  --port 8000
```

### è¯·æ±‚å‚æ•°è¯´æ˜

+ ä½¿ç”¨`vLLM`å’Œ`SGLang`æ—¶ï¼Œå‘é€è¯·æ±‚æ—¶é»˜è®¤å¯ç”¨æ€è€ƒæ¨¡å¼ã€‚å¦‚æœè¦ç¦ç”¨æ€è€ƒå¼€å…³ï¼Œéœ€è¦æ·»åŠ 
  `extra_body={"chat_template_kwargs": {"enable_thinking": False}}`å‚æ•°ã€‚
+ ä¸¤è€…éƒ½æ”¯æŒå·¥å…·è°ƒç”¨ã€‚è¯·ä½¿ç”¨OpenAIé£æ ¼çš„å·¥å…·æè¿°æ ¼å¼è¿›è¡Œè°ƒç”¨ã€‚
+ å…·ä½“ä»£ç è¯·å‚è€ƒ`inference`æ–‡ä»¶å¤¹ä¸­çš„`api_request.py`ã€‚
